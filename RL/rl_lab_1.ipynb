{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "786f28e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cb90e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        self.board = np.zeros((3, 3), dtype=int)\n",
    "        self.done = False\n",
    "\n",
    "    def reset(self):\n",
    "        self.board[:] = 0\n",
    "        self.done = False\n",
    "        return self.board.copy()\n",
    "\n",
    "    def available_actions(self):\n",
    "        return [(i, j) for i in range(3) for j in range(3) if self.board[i, j] == 0]\n",
    "\n",
    "    def step(self, action, player):\n",
    "        i, j = action\n",
    "        if self.board[i, j] != 0:\n",
    "            return self.board.copy(), -10, True  # Invalid move\n",
    "        self.board[i, j] = player\n",
    "        reward, self.done = self.check_winner(player)\n",
    "        return self.board.copy(), reward, self.done\n",
    "\n",
    "    def check_winner(self, player):\n",
    "        for i in range(3):\n",
    "            if all(self.board[i, :] == player) or all(self.board[:, i] == player):\n",
    "                return 1, True\n",
    "        if all(np.diag(self.board) == player) or all(np.diag(np.fliplr(self.board)) == player):\n",
    "            return 1, True\n",
    "        if not self.available_actions():\n",
    "            return 0, True  # Draw\n",
    "        return 0, False  # Game continues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f5d9869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def board_to_tuple(board):\n",
    "    return tuple(board.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "130c061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = {}\n",
    "alpha = 0.1\n",
    "gamma = 0.9\n",
    "epsilon = 0.2\n",
    "episodes = 100000\n",
    "\n",
    "env = TicTacToe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7c1c644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, Q-table size: 8\n",
      "Episode 1000, Q-table size: 896\n",
      "Episode 2000, Q-table size: 1251\n",
      "Episode 3000, Q-table size: 1546\n",
      "Episode 4000, Q-table size: 1732\n",
      "Episode 5000, Q-table size: 1931\n",
      "Episode 6000, Q-table size: 2057\n",
      "Episode 7000, Q-table size: 2174\n",
      "Episode 8000, Q-table size: 2287\n",
      "Episode 9000, Q-table size: 2371\n",
      "Episode 10000, Q-table size: 2481\n",
      "Episode 11000, Q-table size: 2574\n",
      "Episode 12000, Q-table size: 2640\n",
      "Episode 13000, Q-table size: 2718\n",
      "Episode 14000, Q-table size: 2771\n",
      "Episode 15000, Q-table size: 2851\n",
      "Episode 16000, Q-table size: 2953\n",
      "Episode 17000, Q-table size: 3001\n",
      "Episode 18000, Q-table size: 3053\n",
      "Episode 19000, Q-table size: 3115\n",
      "Episode 20000, Q-table size: 3179\n",
      "Episode 21000, Q-table size: 3233\n",
      "Episode 22000, Q-table size: 3284\n",
      "Episode 23000, Q-table size: 3387\n",
      "Episode 24000, Q-table size: 3451\n",
      "Episode 25000, Q-table size: 3499\n",
      "Episode 26000, Q-table size: 3545\n",
      "Episode 27000, Q-table size: 3582\n",
      "Episode 28000, Q-table size: 3619\n",
      "Episode 29000, Q-table size: 3660\n",
      "Episode 30000, Q-table size: 3690\n",
      "Episode 31000, Q-table size: 3714\n",
      "Episode 32000, Q-table size: 3765\n",
      "Episode 33000, Q-table size: 3824\n",
      "Episode 34000, Q-table size: 3857\n",
      "Episode 35000, Q-table size: 3889\n",
      "Episode 36000, Q-table size: 3916\n",
      "Episode 37000, Q-table size: 3956\n",
      "Episode 38000, Q-table size: 3989\n",
      "Episode 39000, Q-table size: 4020\n",
      "Episode 40000, Q-table size: 4057\n",
      "Episode 41000, Q-table size: 4082\n",
      "Episode 42000, Q-table size: 4142\n",
      "Episode 43000, Q-table size: 4157\n",
      "Episode 44000, Q-table size: 4185\n",
      "Episode 45000, Q-table size: 4199\n",
      "Episode 46000, Q-table size: 4217\n",
      "Episode 47000, Q-table size: 4258\n",
      "Episode 48000, Q-table size: 4292\n",
      "Episode 49000, Q-table size: 4324\n",
      "Episode 50000, Q-table size: 4348\n",
      "Episode 51000, Q-table size: 4374\n",
      "Episode 52000, Q-table size: 4404\n",
      "Episode 53000, Q-table size: 4446\n",
      "Episode 54000, Q-table size: 4486\n",
      "Episode 55000, Q-table size: 4510\n",
      "Episode 56000, Q-table size: 4535\n",
      "Episode 57000, Q-table size: 4544\n",
      "Episode 58000, Q-table size: 4571\n",
      "Episode 59000, Q-table size: 4600\n",
      "Episode 60000, Q-table size: 4629\n",
      "Episode 61000, Q-table size: 4646\n",
      "Episode 62000, Q-table size: 4660\n",
      "Episode 63000, Q-table size: 4690\n",
      "Episode 64000, Q-table size: 4719\n",
      "Episode 65000, Q-table size: 4759\n",
      "Episode 66000, Q-table size: 4776\n",
      "Episode 67000, Q-table size: 4789\n",
      "Episode 68000, Q-table size: 4813\n",
      "Episode 69000, Q-table size: 4839\n",
      "Episode 70000, Q-table size: 4869\n",
      "Episode 71000, Q-table size: 4888\n",
      "Episode 72000, Q-table size: 4907\n",
      "Episode 73000, Q-table size: 4935\n",
      "Episode 74000, Q-table size: 4965\n",
      "Episode 75000, Q-table size: 4991\n",
      "Episode 76000, Q-table size: 5011\n",
      "Episode 77000, Q-table size: 5028\n",
      "Episode 78000, Q-table size: 5042\n",
      "Episode 79000, Q-table size: 5057\n",
      "Episode 80000, Q-table size: 5101\n",
      "Episode 81000, Q-table size: 5113\n",
      "Episode 82000, Q-table size: 5134\n",
      "Episode 83000, Q-table size: 5159\n",
      "Episode 84000, Q-table size: 5172\n",
      "Episode 85000, Q-table size: 5182\n",
      "Episode 86000, Q-table size: 5198\n",
      "Episode 87000, Q-table size: 5213\n",
      "Episode 88000, Q-table size: 5231\n",
      "Episode 89000, Q-table size: 5239\n",
      "Episode 90000, Q-table size: 5268\n",
      "Episode 91000, Q-table size: 5279\n",
      "Episode 92000, Q-table size: 5294\n",
      "Episode 93000, Q-table size: 5308\n",
      "Episode 94000, Q-table size: 5317\n",
      "Episode 95000, Q-table size: 5335\n",
      "Episode 96000, Q-table size: 5363\n",
      "Episode 97000, Q-table size: 5379\n",
      "Episode 98000, Q-table size: 5391\n",
      "Episode 99000, Q-table size: 5409\n",
      "Training complete. Final Q-table size: 5419\n",
      "Sample Q-values: {((np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)), (0, 0)): 0.6560999999999979, ((np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)), (0, 1)): 0.7289999999999983, ((np.int64(1), np.int64(2), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)), (0, 2)): 0.7289999999999983, ((np.int64(1), np.int64(2), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)), (1, 0)): 0.7289999999999983, ((np.int64(1), np.int64(2), np.int64(1), np.int64(2), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)), (1, 2)): 0.6896236613845224, ((np.int64(1), np.int64(2), np.int64(1), np.int64(2), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0)), (1, 1)): 0.3014623752222512, ((np.int64(1), np.int64(2), np.int64(1), np.int64(2), np.int64(2), np.int64(1), np.int64(0), np.int64(0), np.int64(0)), (2, 0)): 0.6878987008334604, ((np.int64(1), np.int64(2), np.int64(1), np.int64(2), np.int64(2), np.int64(1), np.int64(1), np.int64(0), np.int64(0)), (2, 1)): 0.9999999996250644, ((np.int64(1), np.int64(2), np.int64(1), np.int64(2), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)), (1, 1)): 0.8099999999999987, ((np.int64(1), np.int64(2), np.int64(1), np.int64(2), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0)), (1, 2)): 0.899999999999999}\n"
     ]
    }
   ],
   "source": [
    "for ep in range(episodes):\n",
    "    state = env.reset()\n",
    "    player = 1\n",
    "    while True:\n",
    "        state_tuple = board_to_tuple(state)\n",
    "        actions = env.available_actions()\n",
    "        if random.random() < epsilon:\n",
    "            action = random.choice(actions)\n",
    "        else:\n",
    "            qs = [Q.get((state_tuple, a), 0) for a in actions]\n",
    "            action = actions[np.argmax(qs)]\n",
    "        next_state, reward, done = env.step(action, player)\n",
    "        next_state_tuple = board_to_tuple(next_state)\n",
    "        if done:\n",
    "            Q[(state_tuple, action)] = Q.get((state_tuple, action), 0) + alpha * (reward - Q.get((state_tuple, action), 0))\n",
    "            break\n",
    "        else:\n",
    "            next_actions = env.available_actions()\n",
    "            max_next_q = max([Q.get((next_state_tuple, a), 0) for a in next_actions])\n",
    "            Q[(state_tuple, action)] = Q.get((state_tuple, action), 0) + alpha * (reward + gamma * max_next_q - Q.get((state_tuple, action), 0))\n",
    "            state = next_state\n",
    "            player = 3 - player  # Switch player\n",
    "    if ep % 1000 == 0:\n",
    "        print(f\"Episode {ep}, Q-table size: {len(Q)}\")\n",
    "print(\"Training complete. Final Q-table size:\", len(Q))\n",
    "print(\"Sample Q-values:\", {k: Q[k] for k in list(Q)[:10]})  # Display first 10 Q-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e99fce96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_board(board):\n",
    "    symbols = {0: ' ', 1: 'X', 2: 'O'}\n",
    "    for row in board:\n",
    "        print('|'.join(symbols[x] for x in row))\n",
    "        print('-' * 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae011ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_vs_agent():\n",
    "    state = env.reset()\n",
    "    player = 1  # Human is X (1), agent is O (2)\n",
    "    while True:\n",
    "        print_board(state)\n",
    "        if player == 1:\n",
    "            # Human move\n",
    "            try:\n",
    "                move = input(\"Enter your move as row,col (e.g., 0,2): \")\n",
    "                i, j = map(int, move.split(','))\n",
    "                if state[i, j] != 0:\n",
    "                    print(\"Invalid move. Try again.\")\n",
    "                    continue\n",
    "                action = (i, j)\n",
    "            except Exception:\n",
    "                print(\"Invalid input. Try again.\")\n",
    "                continue\n",
    "        else:\n",
    "            # Agent move\n",
    "            state_tuple = board_to_tuple(state)\n",
    "            actions = env.available_actions()\n",
    "            qs = [Q.get((state_tuple, a), 0) for a in actions]\n",
    "            action = actions[np.argmax(qs)]\n",
    "            print(f\"Agent chooses: {action}\")\n",
    "\n",
    "        next_state, reward, done = env.step(action, player)\n",
    "        state = next_state\n",
    "        if done:\n",
    "            print_board(state)\n",
    "            if reward == 1:\n",
    "                print(\"Player\" if player == 1 else \"Agent\", \"wins!\")\n",
    "            elif reward == 0:\n",
    "                print(\"It's a draw!\")\n",
    "            else:\n",
    "                print(\"Invalid move!\")\n",
    "            break\n",
    "        player = 3 - player  # Switch player\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24c854ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | | \n",
      "-----\n",
      " | | \n",
      "-----\n",
      " | | \n",
      "-----\n",
      "X| | \n",
      "-----\n",
      " | | \n",
      "-----\n",
      " | | \n",
      "-----\n",
      "Agent chooses: (0, 1)\n",
      "X|O| \n",
      "-----\n",
      " | | \n",
      "-----\n",
      " | | \n",
      "-----\n",
      "X|O|X\n",
      "-----\n",
      " | | \n",
      "-----\n",
      " | | \n",
      "-----\n",
      "Agent chooses: (2, 1)\n",
      "X|O|X\n",
      "-----\n",
      " | | \n",
      "-----\n",
      " |O| \n",
      "-----\n",
      "X|O|X\n",
      "-----\n",
      " |X| \n",
      "-----\n",
      " |O| \n",
      "-----\n",
      "Agent chooses: (1, 0)\n",
      "X|O|X\n",
      "-----\n",
      "O|X| \n",
      "-----\n",
      " |O| \n",
      "-----\n",
      "X|O|X\n",
      "-----\n",
      "O|X| \n",
      "-----\n",
      "X|O| \n",
      "-----\n",
      "Player wins!\n"
     ]
    }
   ],
   "source": [
    "play_vs_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b176d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
