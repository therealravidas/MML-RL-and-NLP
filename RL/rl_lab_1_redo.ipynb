{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dd5c73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce176321",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        self.board = np.zeros((3, 3), dtype=int)\n",
    "        self.done = False\n",
    "\n",
    "    def reset(self):\n",
    "        self.board[:] = 0\n",
    "        self.done = False\n",
    "        return self.board.copy()\n",
    "\n",
    "    def available_actions(self):\n",
    "        return [(i, j) for i in range(3) for j in range(3) if self.board[i, j] == 0]\n",
    "\n",
    "    def step(self, action, player):\n",
    "        i, j = action\n",
    "        if self.board[i, j] != 0:\n",
    "            return self.board.copy(), -10, True\n",
    "        self.board[i, j] = player\n",
    "        reward, self.done = self.check_winner(player)\n",
    "        return self.board.copy(), reward, self.done\n",
    "\n",
    "    def check_winner(self, player):\n",
    "        for i in range(3):\n",
    "            if all(self.board[i, :] == player) or all(self.board[:, i] == player):\n",
    "                return 1, True\n",
    "        if all(np.diag(self.board) == player) or all(np.diag(np.fliplr(self.board)) == player):\n",
    "            return 1, True\n",
    "        if not self.available_actions():\n",
    "            return 0, True\n",
    "        return 0, False\n",
    "\n",
    "\n",
    "def board_to_tuple(board):\n",
    "    return tuple(board.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73de8f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Encouragement-Exploitation structures ===\n",
    "N = {}   # visit counts: N[(state, action)]\n",
    "R = {}   # average rewards: R[(state, action)]\n",
    "\n",
    "episodes = 500000\n",
    "epsilon = 0.1   # small probability of random exploration\n",
    "env = TicTacToe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e681e6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, N-size: 7, R-size: 7\n",
      "Episode 5000, N-size: 2789, R-size: 2789\n",
      "Episode 10000, N-size: 3737, R-size: 3737\n",
      "Episode 15000, N-size: 4433, R-size: 4433\n",
      "Episode 20000, N-size: 4976, R-size: 4976\n",
      "Episode 25000, N-size: 5422, R-size: 5422\n",
      "Episode 30000, N-size: 5740, R-size: 5740\n",
      "Episode 35000, N-size: 6037, R-size: 6037\n",
      "Episode 40000, N-size: 6232, R-size: 6232\n",
      "Episode 45000, N-size: 6446, R-size: 6446\n",
      "Episode 50000, N-size: 6565, R-size: 6565\n",
      "Episode 55000, N-size: 6736, R-size: 6736\n",
      "Episode 60000, N-size: 6830, R-size: 6830\n",
      "Episode 65000, N-size: 6931, R-size: 6931\n",
      "Episode 70000, N-size: 6988, R-size: 6988\n",
      "Episode 75000, N-size: 7050, R-size: 7050\n",
      "Episode 80000, N-size: 7105, R-size: 7105\n",
      "Episode 85000, N-size: 7152, R-size: 7152\n",
      "Episode 90000, N-size: 7220, R-size: 7220\n",
      "Episode 95000, N-size: 7285, R-size: 7285\n",
      "Episode 100000, N-size: 7328, R-size: 7328\n",
      "Episode 105000, N-size: 7379, R-size: 7379\n",
      "Episode 110000, N-size: 7432, R-size: 7432\n",
      "Episode 115000, N-size: 7469, R-size: 7469\n",
      "Episode 120000, N-size: 7525, R-size: 7525\n",
      "Episode 125000, N-size: 7587, R-size: 7587\n",
      "Episode 130000, N-size: 7622, R-size: 7622\n",
      "Episode 135000, N-size: 7684, R-size: 7684\n",
      "Episode 140000, N-size: 7726, R-size: 7726\n",
      "Episode 145000, N-size: 7770, R-size: 7770\n",
      "Episode 150000, N-size: 7812, R-size: 7812\n",
      "Episode 155000, N-size: 7872, R-size: 7872\n",
      "Episode 160000, N-size: 7916, R-size: 7916\n",
      "Episode 165000, N-size: 7953, R-size: 7953\n",
      "Episode 170000, N-size: 7978, R-size: 7978\n",
      "Episode 175000, N-size: 8027, R-size: 8027\n",
      "Episode 180000, N-size: 8070, R-size: 8070\n",
      "Episode 185000, N-size: 8109, R-size: 8109\n",
      "Episode 190000, N-size: 8145, R-size: 8145\n",
      "Episode 195000, N-size: 8183, R-size: 8183\n",
      "Episode 200000, N-size: 8213, R-size: 8213\n",
      "Episode 205000, N-size: 8242, R-size: 8242\n",
      "Episode 210000, N-size: 8285, R-size: 8285\n",
      "Episode 215000, N-size: 8324, R-size: 8324\n",
      "Episode 220000, N-size: 8367, R-size: 8367\n",
      "Episode 225000, N-size: 8409, R-size: 8409\n",
      "Episode 230000, N-size: 8454, R-size: 8454\n",
      "Episode 235000, N-size: 8479, R-size: 8479\n",
      "Episode 240000, N-size: 8522, R-size: 8522\n",
      "Episode 245000, N-size: 8543, R-size: 8543\n",
      "Episode 250000, N-size: 8594, R-size: 8594\n",
      "Episode 255000, N-size: 8611, R-size: 8611\n",
      "Episode 260000, N-size: 8639, R-size: 8639\n",
      "Episode 265000, N-size: 8674, R-size: 8674\n",
      "Episode 270000, N-size: 8686, R-size: 8686\n",
      "Episode 275000, N-size: 8709, R-size: 8709\n",
      "Episode 280000, N-size: 8745, R-size: 8745\n",
      "Episode 285000, N-size: 8783, R-size: 8783\n",
      "Episode 290000, N-size: 8826, R-size: 8826\n",
      "Episode 295000, N-size: 8846, R-size: 8846\n",
      "Episode 300000, N-size: 8879, R-size: 8879\n",
      "Episode 305000, N-size: 8913, R-size: 8913\n",
      "Episode 310000, N-size: 8933, R-size: 8933\n",
      "Episode 315000, N-size: 8956, R-size: 8956\n",
      "Episode 320000, N-size: 8973, R-size: 8973\n",
      "Episode 325000, N-size: 9004, R-size: 9004\n",
      "Episode 330000, N-size: 9031, R-size: 9031\n",
      "Episode 335000, N-size: 9057, R-size: 9057\n",
      "Episode 340000, N-size: 9077, R-size: 9077\n",
      "Episode 345000, N-size: 9107, R-size: 9107\n",
      "Episode 350000, N-size: 9137, R-size: 9137\n",
      "Episode 355000, N-size: 9162, R-size: 9162\n",
      "Episode 360000, N-size: 9187, R-size: 9187\n",
      "Episode 365000, N-size: 9219, R-size: 9219\n",
      "Episode 370000, N-size: 9255, R-size: 9255\n",
      "Episode 375000, N-size: 9281, R-size: 9281\n",
      "Episode 380000, N-size: 9304, R-size: 9304\n",
      "Episode 385000, N-size: 9322, R-size: 9322\n",
      "Episode 390000, N-size: 9355, R-size: 9355\n",
      "Episode 395000, N-size: 9375, R-size: 9375\n",
      "Episode 400000, N-size: 9395, R-size: 9395\n",
      "Episode 405000, N-size: 9412, R-size: 9412\n",
      "Episode 410000, N-size: 9430, R-size: 9430\n",
      "Episode 415000, N-size: 9458, R-size: 9458\n",
      "Episode 420000, N-size: 9494, R-size: 9494\n",
      "Episode 425000, N-size: 9528, R-size: 9528\n",
      "Episode 430000, N-size: 9554, R-size: 9554\n",
      "Episode 435000, N-size: 9574, R-size: 9574\n",
      "Episode 440000, N-size: 9588, R-size: 9588\n",
      "Episode 445000, N-size: 9620, R-size: 9620\n",
      "Episode 450000, N-size: 9664, R-size: 9664\n",
      "Episode 455000, N-size: 9678, R-size: 9678\n",
      "Episode 460000, N-size: 9713, R-size: 9713\n",
      "Episode 465000, N-size: 9737, R-size: 9737\n",
      "Episode 470000, N-size: 9752, R-size: 9752\n",
      "Episode 475000, N-size: 9774, R-size: 9774\n",
      "Episode 480000, N-size: 9806, R-size: 9806\n",
      "Episode 485000, N-size: 9823, R-size: 9823\n",
      "Episode 490000, N-size: 9827, R-size: 9827\n",
      "Episode 495000, N-size: 9853, R-size: 9853\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "for ep in range(episodes):\n",
    "    state = env.reset()\n",
    "    player = 1\n",
    "\n",
    "    while True:\n",
    "        state_tuple = board_to_tuple(state)\n",
    "        actions = env.available_actions()\n",
    "\n",
    "        # --- Encourage unexplored actions ---\n",
    "        unexplored = [a for a in actions if (state_tuple, a) not in N]\n",
    "\n",
    "        if unexplored:\n",
    "            action = random.choice(unexplored)  # encourage exploration\n",
    "        else:\n",
    "            # Exploitation: choose action with best average reward\n",
    "            if random.random() < epsilon:\n",
    "                action = random.choice(actions)\n",
    "            else:\n",
    "                values = [R.get((state_tuple, a), 0) for a in actions]\n",
    "                action = actions[np.argmax(values)]\n",
    "\n",
    "        # Step environment\n",
    "        next_state, reward, done = env.step(action, player)\n",
    "        key = (state_tuple, action)\n",
    "\n",
    "        # Update visit count and running average reward\n",
    "        N[key] = N.get(key, 0) + 1\n",
    "        R[key] = R.get(key, 0) + (reward - R.get(key, 0)) / N[key]\n",
    "\n",
    "        state = next_state\n",
    "        if done:\n",
    "            break\n",
    "        player = 3 - player\n",
    "\n",
    "    if ep % 5000 == 0:\n",
    "        print(f\"Episode {ep}, N-size: {len(N)}, R-size: {len(R)}\")\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab691147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |   |  \n",
      "-----\n",
      "  |   |  \n",
      "-----\n",
      "  |   |  \n",
      "  |   |  \n",
      "-----\n",
      "  | X |  \n",
      "-----\n",
      "  |   |  \n",
      "Agent chooses: (0, 0)\n",
      "O |   |  \n",
      "-----\n",
      "  | X |  \n",
      "-----\n",
      "  |   |  \n",
      "O |   | X\n",
      "-----\n",
      "  | X |  \n",
      "-----\n",
      "  |   |  \n",
      "Agent chooses: (0, 1)\n",
      "O | O | X\n",
      "-----\n",
      "  | X |  \n",
      "-----\n",
      "  |   |  \n",
      "O | O | X\n",
      "-----\n",
      "  | X |  \n",
      "-----\n",
      "X |   |  \n",
      "Player wins!\n"
     ]
    }
   ],
   "source": [
    "def print_board(board):\n",
    "    symbols = {0: ' ', 1: 'X', 2: 'O'}\n",
    "    for i in range(3):\n",
    "        print(\" | \".join(symbols[x] for x in board[i]))\n",
    "        if i < 2:\n",
    "            print(\"-----\")\n",
    "\n",
    "\n",
    "def play_vs_agent():\n",
    "    state = env.reset()\n",
    "    player = 1  # human = X\n",
    "    while True:\n",
    "        print_board(state)\n",
    "\n",
    "        if player == 1:  # human turn\n",
    "            try:\n",
    "                move = input(\"Enter your move (row,col): \")\n",
    "                i, j = map(int, move.split(','))\n",
    "                if state[i, j] != 0:\n",
    "                    print(\"Invalid move. Try again.\")\n",
    "                    continue\n",
    "                action = (i, j)\n",
    "            except:\n",
    "                print(\"Invalid input. Try again.\")\n",
    "                continue\n",
    "        else:  # agent turn (O)\n",
    "            actions = env.available_actions()\n",
    "            state_tuple = board_to_tuple(state)\n",
    "            unexplored = [a for a in actions if (state_tuple, a) not in N]\n",
    "\n",
    "            if unexplored:\n",
    "                action = random.choice(unexplored)\n",
    "            else:\n",
    "                values = [R.get((state_tuple, a), 0) for a in actions]\n",
    "                action = actions[np.argmax(values)]\n",
    "            print(f\"Agent chooses: {action}\")\n",
    "\n",
    "        next_state, reward, done = env.step(action, player)\n",
    "        state = next_state\n",
    "\n",
    "        if done:\n",
    "            print_board(state)\n",
    "            if reward == 1:\n",
    "                print(\"Player wins!\" if player == 1 else \"Agent wins!\")\n",
    "            elif reward == 0:\n",
    "                print(\"It's a draw!\")\n",
    "            else:\n",
    "                print(\"Invalid move. You lose.\")\n",
    "            break\n",
    "\n",
    "        player = 3 - player\n",
    "\n",
    "\n",
    "# Start playing\n",
    "play_vs_agent()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788b2abf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mml-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
